# TIL 20240117

24년 01월 17일 TIL(Today I Learned)

## 1. Fastapi 비동기

### HTTP Get과 Post 차이

##### Get
>- 서버에서 데이터를 받아오기 위해 자주 활용됨
>- 요청할 때 데이터 전송시 URL 주소 끝에 파라미터 값으로 전송되며 이를 Query String이라고 함
>- 예를들어, `https://aaaa.com/60?name=isakin` 과 같다
>- HTTP Body에 담아서 전송하지 않는다

##### Post
>- 리소스를 생성/업데이트 하도록 설계된 방법
>- 필요 데이터를 http body에 전송하므로 url로 데이터가 노출되지 않는다

### 비동기 asynchoronous def 함수(async def)

>"만약, await를 호출하도록 가이드하는 third party 라이브러리를 사용하는 경우 asnyc def를 사용하고 그렇지 않은 경우에는 def와 같이 정상적으로 사용하세요. 잘 모르겠으면 일반적인 정의(def)를 사용하세요. 어떠한 경우에도 FastAPI는 비동기적으로 작동하고 매우 빠릅니다."

- `def`건 `async def`건 둘 다 사용하면 비동기적으로 작동한다.
- 파이썬은 비동기 코드를 코루틴으로 `asnyc`와 `await`로 지원하기 때문에 이것들을 지원하기 위함
- 잘 모르겠다면 동기 방식을 사용하는 것을 권장
- 동기/비동기 방식을 혼용하여 사용하는 것도 가능

##### 올바르지 않은 방법
```python
asnyc def some_library(num: int, something: str):
	s = 0
	for i in range(num):
		print("something.. : ", something, i)
		time.sleep(1)
		s += 1
	return s

app = FastAPI()

@app.post('/')
async def read_results(something: str):
	s1 = await some_library(5, something)
	return {'data': 'data', 's1': s1}
```

```
something.. : 25 0
something.. : 25 1
something.. : 25 2
something.. : 25 3
something.. : 25 4

something.. : 56 0
something.. : 56 1
something.. : 56 2
```
`time.sleep()`은 이런 방법으로는 비동기적으로 처리할 수 없기 때문

##### 올바른 방법
```python
asnyc def some_library(num: int, something: str):
	s = 0
	for i in range(num):
		print("something.. : ", something, i)
		await asyncio.sleep(1)
		s += 1
	return s

app = FastAPI()

@app.post('/')
async def read_results(something: str):
	s1 = await some_library(5, something)
	return {'data': 'data', 's1': s1}
```

```
something.. : 4 0
something.. : 56 0
something.. : 4 1
something.. : 56 1
something.. : 4 2
something.. : 56 2
something.. : 4 3
something.. : 4 4
```


참고 : [비동기(Asynchronous) async 함수에 대하여](https://lsjsj92.tistory.com/649)

## 2. LangChain 비동기


**(1) Standard Interface: invoke(), stream(), batch()**
**(2) Async Interface: ainvoke(), astream(), abatch(), astream_log()**

### Standard Interface

표준 인터페이스에는 invoke(), stream(), batch()가 있다. 표준 인터페이스는 LLM 모델 체인을 정의하고 표준 방식으로 호출(call a chain in a standard way)하는 것을 쉽게 만들어준다. 

```python
import os

from langchain.llms import OpenAI
from langchain_core.output_parsers import StrOutputParser

os.environ["OPENAI_API_KEY"]="sk-xxxx...." # set with yours

llm = OpenAI()
parser = StrOutputParser()

chain = llm | parser
```

**invoke(): 입력에 대해 체인을 호출함**
```python
# invoke(): call the chain on an input
chain.invoke("What are some colors of rainbow?")

# The colors of the rainbow are red, orange, yellow, green, blue, indigo, and violet.
```

**stream(): 응답의 청크(chunk)를 스트리밍함**
```python
# stream(): stream back chunks of the response
for chunk in chain.stream(
    "What are some colors of rainbow? Only answer the colors one by one per a line."):
    print(chunk, end="",  flush=True)
    
# Red
# Orange
# Yellow
# Green
# Blue
# Indigo
# Violet
```
>참고로, flush=True를 설정하면 응답 텍스트가 출력되자마자 버퍼를 비워서 즉시 화면에 출력된다. 설정하지 않으면 파이썬은 자체적으로 적절한 시점에서 버퍼를 비울 때까지 데이터를 버퍼에 저장한다. 이를 통해 프로그램이 실행되는 동안 실시간으로 데이터를 출력하거나 로깅을 할 때 유용하게 사용할 수 있음.

**batch(): 입력 리스트 (a list of inputs)에 대해 체인을 호출함**
```python
# batch(): call the chain on a list of inputs
chain.batch([
    "What are some colors of rainbow?", 
    "Where is the capital city of South Korea?", 
    "When did the World War II happen?"
])

# ['\n\nThe colors of the rainbow are red, orange, yellow, green, blue, indigo, and violet.', 
# '\n\nThe capital city of South Korea is Seoul.', '
# \n\nWorld War II began on September 1, 1939, when Nazi Germany invaded Poland.']
```


### Async Interface

`async` 키워드는 **비동기 프로그래밍(Asynchronous programming)** 을 말한다. 이 함수는 비동기 함수로 정의되었으며, 이 함수 안에서 `await` 키워드를 사용하여 다른 비동기 함수가 완료될 때까지 기다릴 수 있다. 이를 통해 동시성 및 병렬성을 활용하여 더 효율적인 프로그램을 작성할 수 있습니다.  
예를 들어, 네트워크 요청이나 파일 입출력과 같은 I/O 작업을 수행할 때 비동기 프로그래밍은 프로그램이 블록되지 않고 다른 작업을 수행할 수 있게 해준다.

**ainvoke(): 입력에 대해 체인을 비동기적으로 호출함**
```python
# ainvoke(): call the chain on an input async
await chain.ainvoke("What are some colors of rainbow?")

# '\n\nThe colors of the rainbow are red, orange, yellow, green, blue, indigo, and violet.'
```

**astream(): 응답의 청크를 비동기적으로 스트리밍함**
```python
# astream(): stream back chunks of the response async
async for chunk in chain.astream(
    "What are some colors of rainbow? Only answer the colors one by one per a line."):
    print(chunk)
    
#
#
# Red
#
#
# Orange
#
#
# Yellow
#
#
# Green
#
# Blue
# Indigo
# Violet
```

**abatch(): 입력 리스트(a list of inputs)에 대해 체인을 비동기적으로 호출함**
```python
# abatch(): call the chain on a list of inputs async
await chain.abatch([
    "What are some colors of rainbow?", 
    "Where is the capital city of South Korea?", 
    "When did the World War II happen?"
])

# ['\n\n-Red\n-Orange\n-Yellow\n-Green\n-Blue\n-Indigo\n-Violet',
#  '\n\nThe capital city of South Korea is Seoul.',
#  '\n\nWorld War II began on September 1, 1939, when Nazi Germany invaded Poland.']
```

**astream_log(): 최종 응답뿐만 아니라 중간 단계 로그를 그때 그때 스트리밍함**
```python
# astream_log(): stream back intermediate steps as they happen, in addition to the final response
async for chunk in chain.astream_log(
    "What are some colors of rainbow? Only answer the colors one by one per a line."):
    print("---" * 20)
    print(chunk)
    
# ------------------------------------------------------------
# RunLogPatch({'op': 'replace',
#   'path': '',
#   'value': {'final_output': None,
#             'id': '98250f70-4772-4afe-9e3e-e815b1c0ca78',
#             'logs': {},
#             'streamed_output': []}})
# ------------------------------------------------------------
# RunLogPatch({'op': 'add',
#   'path': '/logs/OpenAI',
#   'value': {'end_time': None,
#             'final_output': None,
#             'id': '7b2ca22e-71e0-4a03-9775-801f6c92f3d6',
#             'metadata': {},
#             'name': 'OpenAI',
#             'start_time': '2024-01-06T12:08:35.661',
#             'streamed_output_str': [],
#             'tags': ['seq:step:1'],
#             'type': 'llm'}})
# ------------------------------------------------------------
# RunLogPatch({'op': 'add',
#   'path': '/logs/StrOutputParser',
#   'value': {'end_time': None,
#             'final_output': None,
#             'id': 'abebbbcd-7c1c-4af3-8a47-54c67df34bb8',
#             'metadata': {},
#             'name': 'StrOutputParser',
#             'start_time': '2024-01-06T12:08:36.061',
#             'streamed_output_str': [],
#             'tags': ['seq:step:2'],
#             'type': 'parser'}})
# ------------------------------------------------------------
# RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': '\n'},
#  {'op': 'replace', 'path': '/final_output', 'value': '\n'})
# ------------------------------------------------------------
# RunLogPatch({'op': 'add', 'path': '/logs/OpenAI/streamed_output_str/-', 'value': '\n'})
# ------------------------------------------------------------
# RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': '\n'},
#  {'op': 'replace', 'path': '/final_output', 'value': '\n\n'})
# ------------------------------------------------------------
# RunLogPatch({'op': 'add', 'path': '/logs/OpenAI/streamed_output_str/-', 'value': '\n'})
# ------------------------------------------------------------
# RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': 'Red'},
#  {'op': 'replace', 'path': '/final_output', 'value': '\n\nRed'})
# ------------------------------------------------------------
# RunLogPatch({'op': 'add', 'path': '/logs/OpenAI/streamed_output_str/-', 'value': 'Red'})
# ------------------------------------------------------------
# RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': '\n'},
#  {'op': 'replace', 'path': '/final_output', 'value': '\n\nRed\n'})
# ------------------------------------------------------------
# RunLogPatch({'op': 'add', 'path': '/logs/OpenAI/streamed_output_str/-', 'value': '\n'})
# ------------------------------------------------------------
# RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': 'Orange'},
#  {'op': 'replace', 'path': '/final_output', 'value': '\n\nRed\nOrange'})
# ------------------------------------------------------------
# RunLogPatch({'op': 'add', 'path': '/logs/OpenAI/streamed_output_str/-', 'value': 'Orange'})
# ------------------------------------------------------------
# RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': '\n'},
#  {'op': 'replace', 'path': '/final_output', 'value': '\n\nRed\nOrange\n'})
# ------------------------------------------------------------
# RunLogPatch({'op': 'add', 'path': '/logs/OpenAI/streamed_output_str/-', 'value': '\n'})
# ------------------------------------------------------------
# RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': 'Yellow'},
#  {'op': 'replace', 'path': '/final_output', 'value': '\n\nRed\nOrange\nYellow'})
# ------------------------------------------------------------
# RunLogPatch({'op': 'add', 'path': '/logs/OpenAI/streamed_output_str/-', 'value': 'Yellow'})
# ------------------------------------------------------------
# RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': '\n'},
#  {'op': 'replace',
#   'path': '/final_output',
#   'value': '\n\nRed\nOrange\nYellow\n'})
# ------------------------------------------------------------
# RunLogPatch({'op': 'add', 'path': '/logs/OpenAI/streamed_output_str/-', 'value': '\n'})
# ------------------------------------------------------------
# RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': 'Green\n'},
#  {'op': 'replace',
#   'path': '/final_output',
#   'value': '\n\nRed\nOrange\nYellow\nGreen\n'})
# ------------------------------------------------------------
# RunLogPatch({'op': 'add',
#   'path': '/logs/OpenAI/streamed_output_str/-',
#   'value': 'Green\n'})
# ------------------------------------------------------------
# RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': 'Blue\nIndigo\nViolet'},
#  {'op': 'replace',
#   'path': '/final_output',
#   'value': '\n\nRed\nOrange\nYellow\nGreen\nBlue\nIndigo\nViolet'})
# ------------------------------------------------------------
# RunLogPatch({'op': 'add',
#   'path': '/logs/OpenAI/streamed_output_str/-',
#   'value': 'Blue\nIndigo\nViolet'})
# ------------------------------------------------------------
# RunLogPatch({'op': 'add',
#   'path': '/logs/OpenAI/final_output',
#   'value': {'generations': [[{'generation_info': {'finish_reason': 'stop',
#                                                   'logprobs': None},
#                               'text': '\n'
#                                       '\n'
#                                       'Red\n'
#                                       'Orange\n'
#                                       'Yellow\n'
#                                       'Green\n'
#                                       'Blue\n'
#                                       'Indigo\n'
#                                       'Violet',
#                               'type': 'Generation'}]],
#             'llm_output': None,
#             'run': None}},
#  {'op': 'add',
#   'path': '/logs/OpenAI/end_time',
#   'value': '2024-01-06T12:08:36.322'})
# ------------------------------------------------------------
# RunLogPatch({'op': 'add',
#   'path': '/logs/StrOutputParser/final_output',
#   'value': {'output': '\n\nRed\nOrange\nYellow\nGreen\nBlue\nIndigo\nViolet'}},
#  {'op': 'add',
#   'path': '/logs/StrOutputParser/end_time',
#   'value': '2024-01-06T12:08:36.322'})
```

참고 : [LangChain 표준 인터페이스, 비동기 인터페이스](https://rfriend.tistory.com/844)
